version: 2.1

executors:
  linux-x86_64-cpu:
    docker:
      - image: continuumio/miniconda3
    resource_class: medium+
  linux-arm64-cpu:
    environment:
      CONDA_ARCH: Linux-aarch64
    machine:
      image: ubuntu-2004:current
    resource_class: arm.medium
  macosx-x86_64-cpu:
    environment:
      CONDA_ARCH: MacOSX-x86_64
    macos:
      xcode: 11.7.0  # max supported for conda build, https://circleci.com/docs/using-macos#supported-xcode-versions
  macosx-arm64-cpu:
    environment:
      CONDA_ARCH: MacOSX-arm64
    macos:
      xcode: 14.2.0 # minimum supported for M1
    resource_class: macos.m1.large.gen1
  windows-x86_64-cpu:
    machine:
      image: windows-server-2019-vs2019:stable
      resource_class: windows.medium
      shell: bash.exe

jobs:
  format:
    docker:
      - image: ubuntu:22.04
    steps:
      - checkout
      - run:
          name: Install clang-format
          command: |
            apt-get update
            apt-get install -y git-core clang-format-11
      - run:
          name: Verify clang-format
          command: |
             git ls-files | grep -E  '\.(cpp|h|cu|cuh)$' | xargs clang-format-11 -i
             if git diff --quiet; then
               echo "Formatting OK!"
             else
               echo "Formatting not OK!"
               echo "------------------"
               git --no-pager diff --color
               exit 1
             fi

  build_conda:
    parameters:
      exec:
        type: executor
    executor: << parameters.exec >>
    environment:
      OMP_NUM_THREADS: 10
    steps:
      - checkout
      - run:
          name: Install conda
          command: |
            if [ -n "${CONDA_ARCH}" ]
            then
              curl https://repo.anaconda.com/miniconda/Miniconda3-latest-${CONDA_ARCH}.sh --output miniconda.sh
              bash miniconda.sh -b -p $HOME/miniconda
              ~/miniconda/bin/conda init
            fi
      - run:
          name: Install conda build tools
          command: |
            conda update -y conda
            conda install -y -q conda-build
      - run:
          name: Build/test
          no_output_timeout: 30m
          command: |
            cd conda
            conda build faiss --python 3.10 -c pytorch

  deploy_conda:
    parameters:
      label:
        type: string
        default: main
      exec:
        type: executor
    executor: << parameters.exec >>
    steps:
      - checkout
      - run:
          name: Install conda
          command: |
            if [ -n "${CONDA_ARCH}" ]
            then
              curl https://repo.anaconda.com/miniconda/Miniconda3-latest-${CONDA_ARCH}.sh --output miniconda.sh
              bash miniconda.sh -b -p $HOME/miniconda
              ~/miniconda/bin/conda init
            fi
      - run:
          name: Install conda build tools
          command: |
            conda update -y conda
            conda install -y -q conda-build 
            # anaconda-client
            # conda config --set anaconda_upload yes
      - run:
          name: Build/test/upload
          no_output_timeout: 30m
          environment:
            PACKAGE_TYPE: <<parameters.label>>
          command: |
            cd conda
            conda build faiss --user pytorch --label <<parameters.label>> -c pytorch

  deploy_linux_gpu:
    parameters:
      label:
        type: string
        default: main
      cuda:
        type: string
      cuda_archs:
        type: string
      compiler_version:
        type: string
    machine:
      resource_class: gpu.nvidia.medium
      image: ubuntu-2004-cuda-11.4:202110-01
    steps:
      - checkout
      - run:
          name: Install conda
          command: |
            curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh --output miniconda.sh
            bash miniconda.sh -b -p $HOME/miniconda
            echo 'export PATH=~/miniconda/bin:"$PATH"' >> "$BASH_ENV"
      - run:
          name: Install conda build tools
          command: |
            conda update -y conda
            conda install -y -q conda-build 
            # anaconda-client
            # conda config --set anaconda_upload yes
      - run:
          name: Build/test/upload
          no_output_timeout: 60m
          environment:
            PACKAGE_TYPE: <<parameters.label>>
            CUDA_ARCHS: <<parameters.cuda_archs>>
          command: |
            cd conda
            conda build faiss-gpu --variants '{ "cudatoolkit": "<<parameters.cuda>>", "c_compiler_version": "<<parameters.compiler_version>>", "cxx_compiler_version": "<<parameters.compiler_version>>" }' \
                --user pytorch --label <<parameters.label>> -c pytorch

  build_linux:
    parameters:
      opt_level:
        type: string
        default: generic
      resource_class:
        type: string
        default: medium
    docker:
      - image: ubuntu:22.04
    resource_class: << parameters.resource_class >>
    environment:
      OMP_NUM_THREADS: 10
      MKL_THREADING_LAYER: GNU
    steps:
      - checkout
      - run: 
          name: Set up environment
          command: |
            apt update
            cat .circleci/mkl_debconf_selections | debconf-set-selections
            apt install -y build-essential intel-mkl cmake swig python3-dev python3-numpy python3-scipy python3-pip python3-pytest
      - run:
          name: Build faiss library
          no_output_timeout: 30m
          command: |
            cmake -B build -DBUILD_TESTING=ON -DFAISS_ENABLE_GPU=OFF \
                  -DFAISS_OPT_LEVEL=<< parameters.opt_level >> \
                  -DFAISS_ENABLE_C_API=ON -DPYTHON_EXECUTABLE=$(which python3)\
                  -DCMAKE_BUILD_TYPE=Release -DBLA_VENDOR=Intel10_64_dyn .
            make -k -C build -j$(nproc) faiss
      - when:
          condition:
            equal: [ "avx2", << parameters.opt_level >> ]
          steps:
            - run:
                name: Build faiss_avx2 library
                no_output_timeout: 30m
                command: make -k -C build -j$(nproc) faiss_avx2 swigfaiss_avx2
      - run:
          name: Test faiss library
          command: |
            make -C build -j$(nproc) faiss_test
            export GTEST_OUTPUT="xml:$(realpath .)/test-results/googletest/"
            make -C build test
      - run:
          name: Build python extension
          command: |
            make -C build -j$(nproc) swigfaiss
            cd build/faiss/python
            python3 setup.py build
      - run:
          name: Test python extension
          command: |
            pip3 install torch --extra-index-url https://download.pytorch.org/whl/cpu
            export PYTHONPATH="$(ls -d ./build/faiss/python/build/lib*/)"
            pytest-3 --junitxml=test-results/pytest/results.xml tests/test_*.py
            pytest-3 --junitxml=test-results/pytest/results-torch.xml tests/torch_*.py
      - store_test_results:
          path: test-results
      - run:
          name: Build C API
          command: |
            make -k -C build -j faiss_c

  build_arm:
    machine:
      image: ubuntu-2004:202101-01
    resource_class: arm.medium
    parameters:
      opt_level:
        type: string
        default: generic
    environment:
      OMP_NUM_THREADS: 10
      CONDA_HOME: /home/circleci/miniconda3
      PYTHON: /home/circleci/miniconda3/bin/python
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            sudo apt-get update && sudo apt-get install -y swig
            wget https://repo.anaconda.com/miniconda/Miniconda3-py39_4.9.2-Linux-aarch64.sh
            bash Miniconda3-py39_4.9.2-Linux-aarch64.sh -b -p $CONDA_HOME
            pip3 install cmake
            $CONDA_HOME/bin/conda install -y numpy scipy
            $CONDA_HOME/bin/conda install -y pytorch cpuonly -c pytorch
            $CONDA_HOME/bin/pip install pytest
      - run:
          name: Build faiss library
          command: |
            cmake -B build -DBUILD_TESTING=ON -DFAISS_ENABLE_GPU=OFF \
                  -DFAISS_OPT_LEVEL=<< parameters.opt_level >> \
                  -DFAISS_ENABLE_C_API=ON \
                  -DCMAKE_BUILD_TYPE=Release \
                  -DPython_EXECUTABLE=$PYTHON .
            make -k -C build -j$(nproc) faiss
      - run:
          name: Test faiss library
          command: |
            make -C build -j$(nproc) faiss_test
            export GTEST_OUTPUT="xml:$(realpath .)/test-results/googletest/"
            make -C build test
      - run:
          name: Build python extension
          command: |
            make -C build -j$(nproc) swigfaiss
            cd build/faiss/python
            $PYTHON setup.py build
      - run:
          name: Test python extension
          command: |
            export PYTHONPATH="$(ls -d ./build/faiss/python/build/lib*/)"
            $PYTHON -c "import faiss; assert 'NEON' in faiss.get_compile_options()"
            $PYTHON -m pytest --junitxml=test-results/pytest/results.xml tests/test_*.py
            $PYTHON -m pytest --junitxml=test-results/pytest/results-torch.xml tests/torch_*.py
      - store_test_results:
          path: test-results
      - run:
          name: Build C API
          command: |
            make -k -C build -j faiss_c

  build_linux_gpu:
    machine:
      resource_class: gpu.nvidia.medium
      image: ubuntu-2004-cuda-11.4:202110-01
      docker_layer_caching: true
    steps:
      - checkout
      - run:
          name: Build/test
          command: |
            docker build -t faiss -f .circleci/Dockerfile.faiss_gpu .
            docker run --gpus all faiss make -C build test
            docker run --gpus all faiss sh -c '(pwd; find)'
            docker run --gpus all faiss sh -c '(cd build/faiss/python; python3 setup.py install) && cp tests/common_faiss_tests.py faiss/gpu/test && python3 -m unittest discover -s faiss/gpu/test -p "test_*"'
            docker run --gpus all faiss sh -c '(cd build/faiss/python; python3 setup.py install) && cp tests/common_faiss_tests.py faiss/gpu/test && python3 -m unittest discover -s faiss/gpu/test -p "torch_*.py"'
          no_output_timeout: 60m

workflows:
  version: 2
  build:
    jobs:
      - format:
          name: Format
      - build_linux:
          name: Linux
      - build_linux:
          name: Linux (AVX2)
          opt_level: "avx2"
          resource_class: "medium+"
      - build_conda:
          name: Linux (conda)
          exec: linux-x86_64-cpu
      - build_linux_gpu:
          name: Linux GPU
          requires:
            - Linux
      - build_conda:
          name: OSX
          exec: macosx-x86_64-cpu
      - build_conda:
          name: OSX (ARM)
          exec: macosx-arm64-cpu
      - build_conda:
          name: Windows
          exec: windows-x86_64-cpu
      - build_arm:
          name: ARM64
      - build_conda:
          name: ARM64 (conda)
          exec: linux-arm64-cpu
      - deploy_conda:
          name: Linux packages
          exec: linux-x86_64-cpu
#          filters:
#            tags:
#              only: /^v.*/
#            branches:
#              ignore: /.*/
      - deploy_linux_gpu:
          name: Linux GPU packages (CUDA 11.3)
          cuda: "11.3"
          cuda_archs: "60;61;70;72;75;80;86"
          compiler_version: "9.3"
#          filters:
#            tags:
#              only: /^v.*/
#            branches:
#              ignore: /.*/
      - deploy_conda:
          name: Windows packages
          exec: windows-x86_64-cpu
#          filters:
#            tags:
#              only: /^v.*/
#            branches:
#              ignore: /.*/
      - deploy_conda:
          name: OSX packages
          exec: macosx-x86_64-cpu
#          filters:
#            tags:
#              only: /^v.*/
#            branches:
#              ignore: /.*/
      - deploy_conda:
          name: OSX (ARM) packages
          exec: macosx-arm64-cpu
#          filters:
#            tags:
#              only: /^v.*/
#            branches:
#              ignore: /.*/

  nightly:
    triggers:
      - schedule:
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - main
    jobs:
      - deploy_conda:
          name: Linux nightlies
          exec: linux-x86_64-cpu
          label: nightly
      - deploy_linux_gpu:
          name: Linux GPU nightlies (CUDA 11.3)
          cuda: "11.3"
          cuda_archs: "60;61;70;72;75;80;86"
          compiler_version: "9.3"
          label: nightly
      - deploy_conda:
          name: Windows nightlies
          exec: windows-x86_64-cpu
          label: nightly
      - deploy_conda:
          name: OSX nightlies
          exec: macosx-x86_64-cpu
          label: nightly
      - deploy_conda:
          name: OSX (ARM) nightlies
          exec: macosx-arm64-cpu
          label: nightly
